                  epoch,             train/loss,  metrics/accuracy_top1,  metrics/accuracy_top5,               val/loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                 3.5694,                0.17963,                0.42169,                 3.5678,             0.00023658,             0.00023658,             0.00023658
                      2,                 3.0041,                0.31216,                0.61774,                 3.4766,             0.00045109,             0.00045109,             0.00045109
                      3,                 2.6042,                0.35706,                0.67798,                 3.4187,             0.00064204,             0.00064204,             0.00064204
                      4,                  2.364,                0.39211,                0.69441,                 3.3722,             0.00060797,             0.00060797,             0.00060797
                      5,                 2.1917,                0.42497,                 0.7207,                 3.3421,             0.00057263,             0.00057263,             0.00057263
                      6,                 2.0785,                0.42826,                0.74151,                 3.3224,             0.00053728,             0.00053728,             0.00053728
                      7,                 1.9412,                0.43702,                0.73056,                 3.3188,             0.00050194,             0.00050194,             0.00050194
                      8,                 1.8997,                0.45893,                0.73932,                 3.2922,              0.0004666,              0.0004666,              0.0004666
                      9,                 1.8044,                0.44907,                0.74151,                  3.285,             0.00043126,             0.00043126,             0.00043126
                     10,                 1.7001,                 0.4655,                0.75466,                 3.2775,             0.00039591,             0.00039591,             0.00039591
                     11,                 1.6627,                0.45893,                 0.7437,                  3.279,             0.00036057,             0.00036057,             0.00036057
                     12,                   1.56,                0.48083,                0.75685,                 3.2641,             0.00032523,             0.00032523,             0.00032523
                     13,                 1.5349,                0.46878,                 0.7437,                 3.2559,             0.00028988,             0.00028988,             0.00028988
                     14,                   1.51,                0.47755,                0.75904,                 3.2502,             0.00025454,             0.00025454,             0.00025454
                     15,                 1.4699,                0.48193,                0.75685,                 3.2534,              0.0002192,              0.0002192,              0.0002192
                     16,                  1.438,                0.49069,                0.75246,                 3.2404,             0.00018385,             0.00018385,             0.00018385
                     17,                 1.3823,                0.48959,                0.76013,                   3.24,             0.00014851,             0.00014851,             0.00014851
                     18,                 1.3519,                0.48959,                0.75466,                 3.2325,             0.00011317,             0.00011317,             0.00011317
                     19,                 1.3507,                0.48631,                0.75575,                 3.2354,             7.7826e-05,             7.7826e-05,             7.7826e-05
                     20,                 1.3267,                0.48959,                0.75794,                 3.2361,             4.2483e-05,             4.2483e-05,             4.2483e-05
