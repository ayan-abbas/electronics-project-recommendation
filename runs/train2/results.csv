                  epoch,             train/loss,  metrics/accuracy_top1,  metrics/accuracy_top5,               val/loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                 3.4018,                0.24884,                0.55617,                 3.4545,             0.00023681,             0.00023681,             0.00023681
                      2,                 2.5872,                0.44104,                0.76045,                 3.2804,             0.00045131,             0.00045131,             0.00045131
                      3,                 2.0987,                0.51253,                0.81244,                 3.1878,             0.00064224,             0.00064224,             0.00064224
                      4,                 1.8678,                0.53668,                 0.8273,                 3.1338,             0.00060797,             0.00060797,             0.00060797
                      5,                 1.6704,                0.58496,                0.84123,                 3.0967,             0.00057263,             0.00057263,             0.00057263
                      6,                 1.5396,                0.59796,                 0.8598,                 3.0793,             0.00053728,             0.00053728,             0.00053728
                      7,                 1.4713,                0.60817,                0.86444,                 3.0588,             0.00050194,             0.00050194,             0.00050194
                      8,                 1.3824,                0.63138,                0.87279,                 3.0416,              0.0004666,              0.0004666,              0.0004666
                      9,                  1.301,                0.64067,                0.87929,                 3.0269,             0.00043126,             0.00043126,             0.00043126
                     10,                 1.2319,                0.63974,                0.87929,                 3.0158,             0.00039591,             0.00039591,             0.00039591
                     11,                 1.2213,                0.66202,                0.88301,                  3.004,             0.00036057,             0.00036057,             0.00036057
                     12,                  1.145,                0.65924,                0.88208,                 3.0039,             0.00032523,             0.00032523,             0.00032523
                     13,                 1.0978,                0.65645,                0.88672,                 2.9972,             0.00028988,             0.00028988,             0.00028988
                     14,                 1.0713,                0.67595,                0.88394,                 2.9869,             0.00025454,             0.00025454,             0.00025454
                     15,                 1.0235,                0.66852,                0.88394,                 2.9847,              0.0002192,              0.0002192,              0.0002192
                     16,                 1.0089,                0.68338,                0.88858,                 2.9802,             0.00018385,             0.00018385,             0.00018385
                     17,                0.95279,                0.67038,                0.88858,                 2.9806,             0.00014851,             0.00014851,             0.00014851
                     18,                0.92485,                0.67595,                0.89136,                 2.9721,             0.00011317,             0.00011317,             0.00011317
                     19,                0.91102,                0.67781,                0.88672,                 2.9702,             7.7826e-05,             7.7826e-05,             7.7826e-05
                     20,                0.91786,                0.68338,                0.88951,                 2.9666,             4.2483e-05,             4.2483e-05,             4.2483e-05
